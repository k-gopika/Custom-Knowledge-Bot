import os
from langchain_ollama import ChatOllama

# Load Mistral model via Ollama
llm = ChatOllama(model="mistral")

def classify_intent_mistral(question):
    prompt = f"""
    You are an intent classification expert. Classify the user's question as one of:
    [yes_no, timeline, insight, guidance, general].
    
    Question: "{question}"
    Intent:
    """

    response = llm.invoke(prompt)
    return response.strip()

# --- CLI Loop ---
if __name__ == "__main__":
    print("\nğŸ”® Welcome to the Mistral-Powered Intent Classifier ğŸ”®")
    print("Type your question or type 'exit' to quit.")

    while True:
        user_input = input("\nğŸ“ Enter your question: ").strip()
        if user_input.lower() == "exit":
            print("ğŸ‘‹ Goodbye!")
            break

        intent_mistral = classify_intent_mistral(user_input)
        print(f"\nğŸ¯ Mistral-Classified Intent: {intent_mistral}")
